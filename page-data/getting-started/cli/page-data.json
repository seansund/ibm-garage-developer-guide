{"componentChunkName":"component---src-pages-getting-started-cli-index-mdx","path":"/getting-started/cli/","result":{"pageContext":{"frontmatter":{"title":"Cloud Native Toolkit CLI"},"relativePagePath":"/getting-started/cli/index.mdx","titleType":"page","MdxNode":{"id":"724857ce-60fc-5c94-90d7-7496b52904c9","children":[],"parent":"60def9d1-715f-55e4-b023-047b58bd1611","internal":{"content":"---\ntitle: Cloud Native Toolkit CLI\n---\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nThe <Globals name=\"shortName\" /> Command Line Interface (CLI)\n\n</PageDescription>\n\nThe <Globals name=\"longName\" /> includes the IBM Garage for Cloud (IGC) Command Line Interface (CLI). \nThe [<Globals name=\"igccli\" />](https://github.com/ibm-garage-cloud/ibm-garage-cloud-cli) provides a set of helpful \nutilities that can be invoked from the command line. It was created to automate and simplify complicated and repetitive \ntasks, allowing developers to be more productive.\n\nUse of the CLI is in no way required to work with the <Globals name=\"shortName\" /> and everything done by the CLI can \nbe done manually instead. For each of the commands, the equivalent manual steps are also given for the sake of full \ntransparency and to take away any notion of \"magic\" that the CLI might be performing. \n\nSome of the utilities provided by the CLI include:\n- Register your application's git repo into a CI pipeline ([Jenkins](/guides/continuous-integration), [Tekton](/guides/continuous-integration-tekton), etc.)\n- List the ingress URLs and route URLs defined within the cluster\n- List the connection information (endpoints, user names, and passwords) for the tools configured in the environment\n- Help copy `config maps` and `secrets` into new projects/namespace\n- Enable existing <Globals name=\"templates\" /> with the necessary artifacts to be integrated easily into the <Globals name=\"env\" />\n\nYou can either install the CLI onto your computer or install the Cloud Shell Commands environment.\n\n<Accordion>\n\n<AccordionItem title=\"Install the CLI\" open=\"true\">\n\n<InlineNotification kind=\"warning\">\n\n**Warning:** If you have installed the **IGC** CLI up to `v0.4.0` you must\n uninstall it and follow the installation steps below `npm rm -g @garage\n -catalyst/ibm-garage-cloud-cli`\n \n</InlineNotification>\n\n<br />\n\n<InlineNotification kind=\"warning\">\n\n**Warning:** If you receive an `EACCES` error when you try to install the cli using the instructions that follow, it is an indiction that \nnpm cannot write to the global package directory and that node has not been set up properly on your machine. **DO NOT**\nrerun the command with `sudo`. (Here's an overview of why that's a bad idea - [Don't use sudo with npm](https://medium.com/@ExplosionPills/dont-use-sudo-with-npm-still-66e609f5f92) )\n\nInstead, you need to correct the issue with node. There are two options:\n\n- To fix your current installation, follow [these instructions](http://npm.github.io/installation-setup-docs/installing/a-note-on-permissions.html)\n- To install using Node Version Manager, follow [these instructions](https://github.com/nvm-sh/nvm#installing-and-updating)\n\nOnce npm has been updated, rerun the command to install the cli.\n\n</InlineNotification>\n\n<br />\n\n- Install the CLI:\n    ```bash\n    npm i -g @ibmgaragecloud/cloud-native-toolkit-cli\n    ````\n\n- Verify the version:\n    ```bash\n    igc --version\n    ```\n\n</AccordionItem>\n\n<AccordionItem title=\"Install the Cloud Shell\">\n\nFollow the instructions in the [cloud-shell-commands readme](https://github.com/ibm-garage-cloud/cloud-shell-commands/blob/master/README.md) to install the Cloud Shell Commands.\n\n</AccordionItem>\n\n</Accordion>\n\n## Invoking the CLI\n\nWhen the CLI is installed, it adds an executable named `igc` to the PATH. Running `igc --help` will list\nthe available commands. The output text will be similar to the following:\n\n```bash\n$ igc --help\nIBM Garage Cloud Native Toolkit CLI (https://cloudnativetoolkit.dev)\n\nUsage: igc <command> [args]\n\nCommands:\n  igc console             Launch the IKS or OpenShift admin console\n  igc create-webhook      Create a git webhook for a given Jenkins pipeline\n  igc credentials         Lists the urls and credentials for the tools deployed\n                          to the cluster\n  igc dashboard           Open the Developer Dashboard in the default browser\n  igc enable              Enable the current repository with pipeline logic\n  igc endpoints           List the current ingress hosts for deployed apps in a\n                          namespace      [aliases: ingress, endpoint, ingresses]\n  igc generate-token      Generate a Jenkins api token\n  igc git-secret [name]   Create a kubernetes secret that contains the url,\n                          username, and personal access token for a git repo\n  igc jenkins-auth        Generate a Jenkins api token and register it as\n                          kubernetes secret\n  igc sync [namespace]    Create a namespace (if it doesn't exist) and prepare\n                          it with the necessary configuration\n                                                   [aliases: project, namespace]\n  igc pipeline            Register a pipeline for the current code repository\n  igc tool-config [name]  Create the config map and secret for a tool configured\n                          in the environment\n  igc vlan                Print out the vlan values\n  igc yq <command>        lightweight yaml command-line processor that addresses\n                          deficiencies with the existing `yq` command\n\nOptions:\n  --version  Show version number                                       [boolean]\n  --help     Show help                                                 [boolean]\n```\n\nAs of v0.5.1, the <Globals name=\"igccli\" /> will now install the commands as plugins to the `kubectl` and `oc` CLIs. \nFor example, all of the following are equivalent:\n\n```bash\nigc pipeline\nkubectl pipeline\noc pipeline\n```\n\n### Prerequisite tools\n\n<InlineNotification>\n\nSome of the commands provided by the <Globals name=\"igccli\" /> orchestrate interactions between other CLIs. To get \nstarted please install the [prerequisite tools](/getting-started/prereqs), in particular:\n- The <Globals name=\"kube\" /> CLI\n- The <Globals name=\"ocp\" /> CLI\n- The <Globals name=\"ic\" /> CLI - used to interact with IBM Cloud vlans (not needed if tools will not run on IBM Cloud)\n\n</InlineNotification>\n\n### Log into your cluster\n\nMost all of the commands provided by the <Globals name=\"igccli\" /> interact with a cluster. It probably comes as no \nsurprise then that you should be logged into the prior to running the commands.\n\n<Accordion>\n\n<AccordionItem title=\"OpenShift\" open=\"true\">\n\n```bash\noc login --server=<url> --token=<apikey>\n```\n</AccordionItem>\n\n<AccordionItem title=\"Kubernetes\">\n\n```bash\nibmcloud ks cluster config --cluster <CLUSTER>\n```\n\n</AccordionItem>\n\n\n\n</Accordion>\n\n### Log into your IBM Cloud account\n\nThe `vlan` command provided by the <Globals name=\"igccli\" /> interacts with your IBM Cloud account to\nget the VLAN information needed to create a cluster. The command assumes you have already logged into\nyour account prior to running the command.\n\n- Log into your <Globals name=\"ic\" /> account with the correct region and resource group:\n\n    ```bash\n    ibmcloud login -a cloud.ibm.com -r <region> -g <resource group>\n    ```\n\n## Available commands\n\n### dashboard\n\nOpens the [Developer Dashboard](/getting-started/dashboard) in the default browser. If a default browser has not been \nconfigured, then the URL to the Dashboard will be printed out.\n\nThe dashboard displays the <Globals name=\"shortName\" /> tools configured within the cluster along with links to\nactivation content and links to Starter Kits to start a project quickly.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace where the dashboard has been deployed; the default is `tools`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc dashboard\n```\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands would have the same result on OpenShift:\n\n```shell script\nHOST=$(oc get routes/dashboard -n tools -o jsonpath='{.spec.host}')\nopen \"https://$HOST\"\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands would have the same result on Kubernetes:\n\n```shell script\nHOST=$(kubectl get ingress/developer-dashboard -n tools -o jsonpath='{.spec.rules[0].host}')\nopen \"https://$HOST\"\n```\n\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [credentials](#credentials): shows information about the same tools shown in the dashboard from the \ncommand-line\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### console\n\nOpens the *IKS or OpenShift admin console* in the default browser. If a default browser has not been \nconfigured, then the URL to the console will be printed out.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc console\n```\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands would have the same result on OpenShift:\n\n```shell script\nHOST=$(oc get routes/console -n openshift-console -o jsonpath='{.spec.host}')\nopen \"https://$HOST\"\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands would have the same result on Kubernetes:\n\n```shell script\nREGION=\"...\"\nCLUSTER_NAME=\"...\"\nCLUSTER_ID=$(ibmcloud ks cluster get --cluster ${CLUSTER_NAME} | grep -E \"^ID\" | sed -E \"s/ID: +([^ ]+)/\\\\1/g\")\nopen \"https://${REGION}.containers.cloud.ibm.com/kubeproxy/clusters/${CLUSTER_ID}/service/#/overview?namespace=default\"\n```\n\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [credentials](#credentials): shows information about the same tools shown in the dashboard from the \ncommand-line\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### credentials\n\nLists the endpoints, user names, and passwords for the tools configured in the environment. This is the easiest way to\nget the login credentials for each of the installed tools. Ideally all of the tools would be accessible via SSO at which\npoint this command will be obsolete.\n\nThe command works by reading information available in the cluster. When each tool is installed by the toolkit, a \n`config map` and `secret` are created to store the url and credential for the tool. That information is used in a \nnumber of different ways within the environment:\n\n- Provide configuration information to the pipelines\n- Populate the tiles on the [Developer Dashboard](/getting-started/dashboard)\n- Populate the results of the `credentials` command\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace where the tools have been deployed; the default is `tools`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```shell script\nigc credentials\n```\n\nThe credential output is JSON format like this\n\n```shell script\nCredentials:  {\n  argocd: {\n    user: 'admin',\n    password: '12345678',\n    url: 'https://argocd-tools.mycluster.us-east.containers.appdomain.cloud'\n  },\n  . . .\n  dashboard: {\n    url: 'https://dashboard-tools.mycluster.us-east.containers.appdomain.cloud'\n  },\n  . . .\n}\n```\n\n</Tab>\n<Tab label=\"OpenShift or Kubernetes\">\n\nThe following commands have the same result (note the dependency on `jq`):\n\n```shell script\n# config maps\nkubectl get configmap -n tools -l grouping=garage-cloud-native-toolkit -o json | \\\n  jq '[.items[] | select(.metadata.name != \"ibmcloud-config\").data]'\n\n# secrets\nkubectl get secret -n tools -l grouping=garage-cloud-native-toolkit -o json | \\\n  jq '[.items[] | select(.metadata.name != \"ibmcloud-apikey\").data | with_entries(.value |= @base64d)]'\n```\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [dashboard](#dashboard): displays the url of the Developer Dashboard and launches the default browser\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### endpoints\n\nLists the ingress and/or route URLs for the applications in a given namespace. An attempt will be made to get the \nnamespace from the current context if one is not provided as an argument. Results of the command are provided in an \ninteractive menu. If one of the endpoints is selected, it will display the URL and launch it in the default browser. \nSelecting `Exit` will print the full list of endpoints and exit.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace from which the endpoints will be read; the value will be read from the current context if not \nprovided\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc endpoints\n```\n\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands list the route and ingress endpoints:\n\n```shell script\n# routes\nkubectl get route -n tools\n\n# ingress\nkubectl get ingress -n tools\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands list the ingress endpoints:\n\n```shell script\nkubectl get ingress -n tools\n```\n</Tab>\n</Tabs>\n\n### sync (formerly namespace)\n\nCreates a Kubernetes namespace or OpenShift project (if it doesn't already exist) and sets it up so that the namespace\ncan be used as a target for application deployments and/or to host the <Globals name=\"env\" />. The command performs two\nmajor functions - 1) set up a service account in the namespace with the pull secret(s) for the IBM Container Registry \nand 2) synchronize the `ConfigMaps` and `Secrets` from a template namespace to create a \"development\" namespace. After\nthe command has run successfully it will set the provided namespace in the current context \n(e.g. equivalent to `oc project X`)\n\nThe pull secret(s) are required in order for pods to pull images that are stored in the IBM Container Registry.\nWhen the cluster is created in IBM Cloud, a pull secret is provided in the `default` namespace. In order for a \npod in another namespace to use it, the secret must first be copied into the namespace. After that, the pod either \nneeds to reference the pull secret directly or the service account used by the resource needs to have a reference to\nthe secret. The CLI copies the pull secret over and adds it to the service account so the pod can take either\napproach.\n\nThe other function this command performs is to copy relevant `ConfigMaps` and `Secrets` into the namespace that are\nneeded for development activities. Managing resources across namespaces (particularly `ConfigMaps` and `Secrets`) is a \ncommon challenge in Kubernetes environments. We have provided the command at this time to simplify the steps required \nto get everything ready. Ultimately, this problem seems like an ideal one for an Operator to solve and when one is \navailable (either from the Toolkit or elsewhere) this command will be retired or transitioned.\n\nThere are two different types of namespaces that the command will set up:\n\n- \"release\" namespace where applications can be deployed (e.g. test, staging)\n\n-OR-\n\n- \"development\" namespace where DevOps pipelines can be run and where application components can be deployed \n(e.g. dev)\n\nBoth \"release\" and \"development\" namespaces will have the pull secret(s) created. However, only the \"development\"\nnamespace will also have the `ConfigMaps` and `Secrets` copied over.\n\n**Command flags**\n- `-t`: the template namespace that will be the source of the `config maps` and `secrets`; the default is `tools`\n- `-z`: the name of the service account; the default is `default`\n- `--dev`: flag indicating the namespace should be set for development\n- `--verbose`: flag indicating that the console output should persist on the screen\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nCreate a `test` namespace\n\n```shell script\nigc sync test\n```\n\nCreate a `dev` namespace for development\n\n```shell script\nigc sync dev --dev\n```\n</Tab>\n<Tab label=\"Manual pull secret setup\">\n\nThe following commands will copy the pull secret(s) from the `default` namespace and add them to the service account:\n\n```shell script\nexport NAMESPACE=\"NAMESPACE\"\nexport SERVICE_ACCOUNT=\"default\"\n\nif [[ $(kubectl get secrets -n \"${NAMESPACE}\" -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | grep icr | wc -l | xargs) -eq 0 ]]; then\n    echo \"*** Copying pull secrets from default namespace to ${NAMESPACE} namespace\"\n\n    kubectl get secrets -n default | grep icr | sed \"s/\\([A-Za-z-]*\\) *.*/\\1/g\" | while read default_secret; do\n        kubectl get secret ${default_secret} -n default -o yaml --export | sed \"s/name: default-/name: /g\" | kubectl -n ${NAMESPACE} create -f -\n    done\nelse\n    echo \"*** Pull secrets already exist on ${NAMESPACE} namespace\"\nfi\n\n\nEXISTING_SECRETS=$(kubectl get serviceaccount/${SERVICE_ACCOUNT} -n \"${NAMESPACE}\" -o json  | tr '\\n' ' ' | sed -E \"s/.*imagePullSecrets.: \\[([^]]*)\\].*/\\1/g\" | grep icr | wc -l | xargs)\nif [[ ${EXISTING_SECRETS} -eq 0 ]]; then\n    echo \"*** Adding secrets to serviceaccount/${SERVICE_ACCOUNT} in ${NAMESPACE} namespace\"\n\n    PULL_SECRETS=$(kubectl get secrets -n \"${NAMESPACE}\" -o jsonpath='{ range .items[*] }{ \"{\\\"name\\\": \\\"\"}{ .metadata.name }{ \"\\\"}\\n\" }{ end }' | grep icr | grep -v \"${NAMESPACE}\" | paste -sd \",\" -)\n    kubectl patch -n \"${NAMESPACE}\" serviceaccount/${SERVICE_ACCOUNT} -p \"{\\\"imagePullSecrets\\\": [${PULL_SECRETS}]}\"\nelse\n    echo \"*** Pull secrets already applied to serviceaccount/${SERVICE_ACCOUNT} in ${NAMESPACE} namespace\"\nfi\n```\n</Tab>\n<Tab label=\"Manual ConfigMap and Secret setup\">\n\nThe following steps will copy the `ConfigMaps` and `Secrets` from a template namespace to a target namespace:\n\n```shell script\n  export TEMPLATE_NAMESPACE=\"tools\"\n  export NAMESPACE=\"NAMESPACE\"\n\n  kubectl get configmap -l grouping=garage-cloud-native-toolkit -n ${TEMPLATE_NAMESPACE} -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | \\\n    while read cm; do\n      kubectl get configmap ${cm} --namespace ${TEMPLATE_NAMESPACE} --export -o yaml | \\\n        kubectl apply --namespace $NAMESPACE -f -\n    done\n\n  kubectl get secret -l grouping=garage-cloud-native-toolkit -n ${TEMPLATE_NAMESPACE} -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | \\\n    while read cm; do\n      kubectl get secret ${cm} --namespace ${TEMPLATE_NAMESPACE} --export -o yaml | \\\n        kubectl apply --namespace $NAMESPACE -f -\n    done\n\n```\n</Tab>\n</Tabs>\n\n### pipeline\n\nConnects a branch in a Git repo to a either a Jenkins or Tekton CI pipeline in the <Globals name=\"env\" /> and triggers \nan initial build. A webhook is also created so that when a new commit is added to the branch, the pipeline is triggered\nto start the process to rebuild and redeploy the app using the new code. The Git repo needs to be hosted using a site \nthat supports triggers such as GitHub or GitLab. \n\nThis command requires that the terminal is already logged in to the cluster. It also requires that the terminal's \ncurrent directory is the repository directory for your local copy of the Git repo. The command uses the local Git \nrepo's configuration to find the server copy.\n\nIf Jenkins or Tekton are not specified when the command is invoked then you will be prompted for which CI tool to use. \nThe command will also prompt for the username and personal access token to access the Git repository, unless those are \nprovided as command-line parameters. It will also prompt you for the branch to use to trigger builds; the default \nis the current branch.\n\n**Command flags**\n- `-n`: the deployment namespace; if not provided the namespace from the current context will be used\n- `-u`: the username for accessing the Git repo\n- `-p`: the personal access token for accessing the Git repo\n- `--jenkins`: deploy using a Jenkins pipeline\n- `--tekton`: deploy using a Tekton pipeline\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\nCreate a Jenkins pipeline in the `dev` namespace and prompt for the Git credentials\n\n```shell script\nigc pipeline --jenkins\n```\n\nCreate a Tekton pipeline in the `my-dev` namespace, using the Git credentials `gituser` and `gitpat`\n\n```shell script\nigc pipeline -n my-dev -u gituser -p gitpat --tekton\n```\n</Tab>\n<Tab label=\"Manual Steps for Tekton\">\n\nThe following is the list of steps required to manually configure a **Tekton** \npipeline with your development cluster.\n<br></br>\n\n\n- Configure the service account `pipeline` if it doesn't exist, on OpenShift 4 the operator takes care of this you can skip.\n  ```\n  oc create serviceaccount pipeline\n  oc adm policy add-scc-to-user privileged -z pipeline\n  oc adm policy add-role-to-user edit -z pipeline\n  ```\n- Clone the tasks from the `tools` namespace into the `new-namespace`\n  ```\n  kubectl get tasks --export -o yaml -n tools  | sed s/\"namespace: tools/namespace: $(oc project -q)\"/ | kubectl apply -f -\n  ```\n- Clone the pipelines from the `tools` namespace into the `new-namespace`\n  ```\n  kubectl get pipelines --export -o yaml -n tools  | sed s/\"namespace: tools/namespace: $(oc project -q)\"/ | kubectl apply -f -\n  ```\n\n### Pipeline Resource\n\n- Create a Pipeline resource for the git repository, replace with the correct github url for your repository\n  Use the `tkn` CLI to create `git` resource input the github repo url for `url` and branch for `revision`\n  ```\n  tkn resource create\n  ```\n  Here is the an example of the cli\n  ```\n  tkn resource create\n  ? Enter a name for a pipeline resource : nodejs-typescript-git\n  ? Select a resource type to create : git\n  ? Enter a value for url :  https://github.com/{user or org}/{app}\n  ? Enter a value for revision :  master\n  New git resource \"nodejs-typescript-git\" has been created\n  ```\n- Create a Pipeline resource for the docker image registry, you can use the internal registry in OpenShift or use an external registry like IBM Container Registry (credentials need setup)\n  Use the `tkn` CLI to create `image` resource\n  ```\n  tkn resource create\n  ```\n  Select `image` for type.\n\n  Enter the corresponding `url` for container registry, use the new-namespace} in the url\n\n  For OCP 3 internal registry use `docker-registry.default.svc:5000/{new-namespace}/node-typescript:latest`\n\n  For OCP 4 or CRC internal registry use `image-registry.openshift-image-registry.svc:5000/{new-namespace}/node-typescript:latest`\n\n  For external registry like IBM Container registry based on region use `us.icr.io/{namespace}/node-typescript:latest` use an existing namespace in your IBM Cloud\n  ```\n  tkn resource create\n  ? Enter a name for a pipeline resource : nodejs-typescript-image\n  ? Select a resource type to create : image\n  ? Enter a value for url :  docker-registry.default.svc:5000/dev/node-typescript:latest\n  ? Enter a value for digest :\n  New image resource \"nodejs-typescript-image\" has been created\n  ```\n- Select the pipeline, to show the available pipeline run\n  ```\n  tkn pipeline ls\n  NAME              AGE              LAST RUN   STARTED   DURATION   STATUS\n  igc-java-gradle   33 minutes ago   ---        ---       ---        ---\n  igc-nodejs        33 minutes ago   ---        ---       ---        ---\n  ```\n  In this case use `igc-java-gradle` for java or `igc-nodejs` for nodejs.\n- Run the Pipeline using the `git` and `image` Pipeline resources.\n  Set the following environment variable for convienience:\n  ```\n  export PIPELINE=igc-nodejs\n  export GIT=nodejs-typescript-git\n  export IMAGE=nodejs-typescript-image\n  ```\n  Then run the `tkn pipeline start` with the input arguments using the service account `pipeline`\n  ```\n  tkn pipeline start \\\n  ${PIPELINE} \\\n  -r git-source=${GIT} \\\n  -r docker-image=${IMAGE} \\\n  -s pipeline\n  ```\n\n### Create a Git Webhook\n\n- Open the Tekton Dashboard from the main Tools Dashboard or the ICPA landing page.\n\n- Create a Webhook in the Tekton Dashboard\n    ![Webhook](/images/webhook.png)\n\n    - Click **Webhook** on the menu\n    - Click **Add Webhook** and enter the information for the webhook\n    - Name: **insert name**\n    - Repository UR: **template git repo url**\n    - Access Token: Create github access token with permission minimum write:repo_hook\n    - Namespace: **insert namespace**\n    - Pipeline: select **igc-java-gradle** or **igc-nodejs**\n    - Service Account: **pipeline**\n    - Docker Registry:\n        - For OCP 3 internal registry use `docker-registry.default.svc:5000/{new-namespace}`\n        - For OCP 4 or CRC internal registry use `image-registry.openshift-image-registry.svc:5000/{new-namespace}`\n        - For external registry like IBM Container registry based on region use `us.icr.io/{namespace}` use an existing namespace in your IBM Cloud. Make sure to configure docker credentials in the Tekton Dashboard using your IAM API Key and `iamapikey` for username in your namespace.\n\n- Check that Webhook is created on the Github repository (Settings-Webhooks)\n\n- Make a change to the git repo and push the change to remote git repository or click on **Pipelines**\nand manually kick of a pipeline build\n\n</Tab>\n<Tab label=\"Manual steps for Jenkins on OpenShift\">\n\n### 1. Provision Jenkins ephemeral\n\nJenkins ephemeral provides a kubernetes native version of Jenkins that dynamically provisions build agents on-demand. \nIt's _ephemeral_ meaning it doesn't allocate any persistent storage in the cluster.\n\n1. Set the project/namespace\n\n```shell script\noc project {NAMESPACE}\n```\n\nwhere:\n- `{NAMESPACE}` is the development namespace where the pipelines will run\n\n2. Run the following command to provision the Jenkins instance in your namespace\n\n```shell script\noc new-app jenkins-ephemeral\n```\n\n3. Open the OpenShift console as described in the login steps above\n\n4. Select `Workloads -> Pods` from the left-hand menu\n\n5. At the top of the page select your project/namespace from the drop-down list to see the Jenkins instance running\n\n### 2. Give the `jenkins` service account `privileged` access\n\nAll of the <Globals name=\"shortName\"/> pipelines use `buildah` to build and push the container image to the registry. \nUnfortunately, the `buildah` container must run as root. By default, OpenShift does not allow containers to run as the \nroot user and special permission is required for the pipeline to run.\n\nWith the Jenkins build engine, all the build processes run as the `jenkins` service account. In order for the pipeline \ncontainer to run as root on OpenShift we will need to give the `privileged` security context constraint (scc) to \n`jenkins` service account with the following command:\n\n```shell script\noc project {NAMESPACE}\noc adm policy add-scc-to-user privileged -z jenkins\n```\n\nwhere:\n - `{NAMESPACE}` should be the name you claimed in the box note prefixed to `-dev` (e.g. user01-dev)\n\n### 3. Create a secret with git credentials\n\nIn order for Jenkins to have access to the git repository, particularly if it is a private repository, a Kubernetes \nsecret needs to be added that contains the git credentials.\n\n1. Create a personal access token (if you don't already have one) using the prereq instructions - \nhttps://cloudnativetoolkit.dev/getting-started/prereqs#configure-github-personal-access-token\n\n2. Copy the following into a file called `gitsecret.yaml` and update the {Git-Username}, and {Git-PAT}\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  annotations:\n    build.openshift.io/source-secret-match-uri-1: https://github.com/*\n  labels:\n    jenkins.io/credentials-type: usernamePassword\n  name: git-credentials\ntype: kubernetes.io/basic-auth\nstringData:\n  username: {Git-Username}\n  password: {Git-PAT}\n```\n\nwhere:\n - `Git-Username` is the username that has access to the git repo\n - `Git-PAT` is the personal access token of the git user\n\n2. After logging into the cluster, create the secret by running the following:\n\n```shell script\noc project {NAMESPACE}\noc create -f gitsecret.yaml\n```\n\nwhere:\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n### 3. Create the build config\n\nOn OpenShift 4.3, Jenkins is built into the OpenShift console and the build pipelines can be managed using Kubernetes \ncustom resources. The following steps will create one by hand to create the build pipeline for the new application.\n\n1. Copy the following into a file called `buildconfig.yaml` and update the {Name}, {Secret}, {Git-Repo-URL}, \nand {Namespace}\n\n```yaml\napiVersion: v1\nkind: BuildConfig\nmetadata:\n  name: {Name}\nspec:\n  triggers:\n  - type: GitHub\n    github:\n      secret: my-secret-value\n  source:\n    git:\n      uri: {Git-Repo-URL}\n      ref: master\n  strategy:\n    jenkinsPipelineStrategy:\n      jenkinsfilePath: Jenkinsfile\n      env:\n      - name: CLOUD_NAME\n        value: openshift\n      - name: NAMESPACE\n        value: {NAMESPACE}\n```\n\nwhere:\n - `Name` is in the name of your pipeline \n - `Git-Repo-URL` is the https url to the git repository\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n2. Assuming you are still logged into the cluster, create the buildconfig resource in the cluster\n\n```shell script\noc project {NAMESPACE}\noc create -f buildconfig.yaml\n```\n\nwhere:\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n### 4. View the pipeline in the OpenShift console\n\n1. Open the OpenShift console for the cluster\n2. Select Builds -> Build Config\n3. Select your project/namespace (i.e. `{NAMESPACE}`) from the top\n4. The build pipeline that was created in the previous step should appear\n5. Manually trigger the pipeline by selecting `Start Build` the menu button on the right side of the row\n\n### 5. Create the webhook\n\n1. Run the following to get the webhook details from the build config \n\n```\noc project {NAMESPACE}\noc describe bc {Name}\n```\n\nwhere:\n - `{Name}` is the name used in the previous step for the build config\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\nThe webhook url will have a structure similar to:\n\n`http://{openshift_api_host:port}/oapi/v1/namespaces/{namespace}/buildconfigs/{name}/webhooks/{secret}/generic`\n\nIn this case `{secret}` will be `my-secret-value`\n\n2. Open a browser to the GitHub repo deployed in the previous step in the build config\n\n3. Select `Settings` then `Webhooks`. Press `Add webhook`\n\n4. Paste the webhook url from the previous step into the `Payload url`\n\n5. Set the content-type to `application/json` and leave the rest of the values as the defaults\n\n6. Press `Add webhook` to create the webhook\n\n7. Press the button to test the webhook to ensure that everything was done properly\n\n8. Go back to your project code and push a change to one of the files\n   \n9. Go to the Build pipeline page in the OpenShift console to see that the build was triggered\n\n</Tab>\n<Tab label=\"Manual steps for Jenkins on Kubernetes\">\n\nTBD\n\n</Tab>\n</Tabs>\n\n### enable\n\nAdds DevOps artifacts to a Git repo that the <Globals name=\"env\" /> uses to deploy the app. The command displays a \nlist of available pipelines and applies the one you select to your code repo. The DevOps files added to your repo\n include (but are not limited to):\n\n- Helm chart\n- Jenkinsfile\n\nThis command DOES NOT require that the terminal is already logged in to an IBM Cloud account nor the cluster. It DOES\nrequire that the terminal's current directory is the repository directory for your local copy of the Git repo.\n\nThe command will add files to the local repo. You should commit these new files and push them to the server repo. \nThen run `igc pipeline` to connect your repo to a pipeline in the environment.\n\n**Command flags**\n- `--repo`: the set of pipelines to choose from; the default is https://github.com/ibm-garage-cloud/garage-pipelines\n- `-p`: the name of the pipeline that should be installed; if not provided then you will be prompted\n- `-b`: the branch from which the pipeline should be installed; the default is `stable` \n- `r`: the version number of the pipeline that should be installed; the default is `latest`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\n1. Before running the command, make sure you have a clean repository with no unstaged changes. Either commit any\nchanges or stash them temporarily with `git stash`. It is particularly important that any changes to the pipeline be\ndealt with.\n\n2. Apply the pipeline updates using the CLI command\n\n```shell script\nigc enable\n```\n\n3. Review the changes using `git diff` and revert any application-specific changes that should remain (e.g. \ncustomization to the Jenkins pipeline in the `Jenkinsfile`, specific values added to `values.yaml`, customizations\nto the templates in the `helm chart`)\n\n4. Commit the changes when you are happy with them\n\n</Tab>\n<Tab label=\"Manual steps\">\n\nThe follow provides the manual steps equivalent to the `igc enable` command:\n\n1. Before updating the pipelines, make sure you have a clean repository with no unstaged changes. Either commit any\nchanges or stash them temporarily with `git stash`. It is particularly important that any changes to the pipeline be\ndealt with.\n\n2. Download the `index.yaml` file containing the available pipeline versions\n\n    ```shell script\n    curl -O https://ibm-garage-cloud.github.io/garage-pipelines/index.yaml\n    ```\n\n3. Look through the `index.yaml` file to identify the url for the desired pipeline branch and version\n\n4. With the PIPELINE_URL from the previous step, run the following to download the pipeline tar-ball\n\n    ```shell script\n    curl -O ${PIPELINE_URL}\n    ```\n\n5. Extract the tar-ball into your repository directory. You will be prompted to overwrite files. Overwrite as\nappropriate\n\n    ```shell script\n    tar xzf ${PIPELINE_FILE}\n    ```\n\n6. Review the changes using `git diff` and revert any application-specific changes that should remain (e.g. \ncustomization to the Jenkins pipeline in the `Jenkinsfile`, specific values added to `values.yaml`, customizations\nto the templates in the `helm chart`)\n\n7. Commit the changes when you are happy with them\n\n</Tab>\n</Tabs>\n\n### tool-config\n\nConfigures a new tool in the environment. After deploying the tool, use this command to add the tool to the list of \ncredentials so that it will be displayed in the dashboard.\n\n**Command flags**\n- The name for the tool\n- `-n`: the tools namespace; the default is `tools`\n- `--url`: the endpoint for accessing the tool, usually its dashboard\n- `--username`: (optional) the user name for logging into to tool\n- `--password`: (optional) the password for logging into to tool\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe following gives an example of using the `tool-config` command to set up a tool named `my-tool` with its \ndashboard's endpoint and credentials\n\n```shell script\nigc tool-config my-tool \\\n  --url https://mytool-dashboard.mycluster.us-east.containers.appdomain.cloud \\\n  --username admin \\\n  --password password\n```\n\n</Tab>\n<Tab label=\"Manual install with helm\">\n\nThe following gives an example of using helm directly to do the equivalent (using helm 3):\n\n```shell script\nhelm install my-tool tool-config \\\n  --repo https://ibm-garage-cloud.github.io/toolkit-charts/ \\\n  --set url=https://mytool-dashboard.mycluster.us-east.containers.appdomain.cloud \\\n  --set username=admin \\\n  --set password=password\n```\n</Tab>\n</Tabs>\n\n### vlan\n\nLists the VLANs for a particular IBM Cloud region. This information is useful for preparing Terraform cluster creation \nsteps. The command reads all the data centers in the region and allows you to select the appropriate data center for\nthe vlan. \n\nThis command requires that the terminal is already logged in to the cloud region. It does NOT need to be logged in to a cluster.\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nList a pair of public/private VLANs for a new environment to use\n\n```shell script\nigc vlan\n```\n\n</Tab>\n<Tab label=\"Manual steps\">\n\n1. List the zones for the region\n    ```shell script\n    ibmcloud ks zones --region-only --provider classic\n    ```\n\n2. Select the desired zone from the listing provided by the previous command and run the following to list the\nvlans for that zone\n\n    ```shell script\n    ibmcloud ks vlans --zone ${zone}\n    ```\n\n</Tab>\n</Tabs>\n","type":"Mdx","contentDigest":"66c0566d095f058925b62f178cfbedff","counter":551,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Cloud Native Toolkit CLI"},"exports":{},"rawBody":"---\ntitle: Cloud Native Toolkit CLI\n---\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nThe <Globals name=\"shortName\" /> Command Line Interface (CLI)\n\n</PageDescription>\n\nThe <Globals name=\"longName\" /> includes the IBM Garage for Cloud (IGC) Command Line Interface (CLI). \nThe [<Globals name=\"igccli\" />](https://github.com/ibm-garage-cloud/ibm-garage-cloud-cli) provides a set of helpful \nutilities that can be invoked from the command line. It was created to automate and simplify complicated and repetitive \ntasks, allowing developers to be more productive.\n\nUse of the CLI is in no way required to work with the <Globals name=\"shortName\" /> and everything done by the CLI can \nbe done manually instead. For each of the commands, the equivalent manual steps are also given for the sake of full \ntransparency and to take away any notion of \"magic\" that the CLI might be performing. \n\nSome of the utilities provided by the CLI include:\n- Register your application's git repo into a CI pipeline ([Jenkins](/guides/continuous-integration), [Tekton](/guides/continuous-integration-tekton), etc.)\n- List the ingress URLs and route URLs defined within the cluster\n- List the connection information (endpoints, user names, and passwords) for the tools configured in the environment\n- Help copy `config maps` and `secrets` into new projects/namespace\n- Enable existing <Globals name=\"templates\" /> with the necessary artifacts to be integrated easily into the <Globals name=\"env\" />\n\nYou can either install the CLI onto your computer or install the Cloud Shell Commands environment.\n\n<Accordion>\n\n<AccordionItem title=\"Install the CLI\" open=\"true\">\n\n<InlineNotification kind=\"warning\">\n\n**Warning:** If you have installed the **IGC** CLI up to `v0.4.0` you must\n uninstall it and follow the installation steps below `npm rm -g @garage\n -catalyst/ibm-garage-cloud-cli`\n \n</InlineNotification>\n\n<br />\n\n<InlineNotification kind=\"warning\">\n\n**Warning:** If you receive an `EACCES` error when you try to install the cli using the instructions that follow, it is an indiction that \nnpm cannot write to the global package directory and that node has not been set up properly on your machine. **DO NOT**\nrerun the command with `sudo`. (Here's an overview of why that's a bad idea - [Don't use sudo with npm](https://medium.com/@ExplosionPills/dont-use-sudo-with-npm-still-66e609f5f92) )\n\nInstead, you need to correct the issue with node. There are two options:\n\n- To fix your current installation, follow [these instructions](http://npm.github.io/installation-setup-docs/installing/a-note-on-permissions.html)\n- To install using Node Version Manager, follow [these instructions](https://github.com/nvm-sh/nvm#installing-and-updating)\n\nOnce npm has been updated, rerun the command to install the cli.\n\n</InlineNotification>\n\n<br />\n\n- Install the CLI:\n    ```bash\n    npm i -g @ibmgaragecloud/cloud-native-toolkit-cli\n    ````\n\n- Verify the version:\n    ```bash\n    igc --version\n    ```\n\n</AccordionItem>\n\n<AccordionItem title=\"Install the Cloud Shell\">\n\nFollow the instructions in the [cloud-shell-commands readme](https://github.com/ibm-garage-cloud/cloud-shell-commands/blob/master/README.md) to install the Cloud Shell Commands.\n\n</AccordionItem>\n\n</Accordion>\n\n## Invoking the CLI\n\nWhen the CLI is installed, it adds an executable named `igc` to the PATH. Running `igc --help` will list\nthe available commands. The output text will be similar to the following:\n\n```bash\n$ igc --help\nIBM Garage Cloud Native Toolkit CLI (https://cloudnativetoolkit.dev)\n\nUsage: igc <command> [args]\n\nCommands:\n  igc console             Launch the IKS or OpenShift admin console\n  igc create-webhook      Create a git webhook for a given Jenkins pipeline\n  igc credentials         Lists the urls and credentials for the tools deployed\n                          to the cluster\n  igc dashboard           Open the Developer Dashboard in the default browser\n  igc enable              Enable the current repository with pipeline logic\n  igc endpoints           List the current ingress hosts for deployed apps in a\n                          namespace      [aliases: ingress, endpoint, ingresses]\n  igc generate-token      Generate a Jenkins api token\n  igc git-secret [name]   Create a kubernetes secret that contains the url,\n                          username, and personal access token for a git repo\n  igc jenkins-auth        Generate a Jenkins api token and register it as\n                          kubernetes secret\n  igc sync [namespace]    Create a namespace (if it doesn't exist) and prepare\n                          it with the necessary configuration\n                                                   [aliases: project, namespace]\n  igc pipeline            Register a pipeline for the current code repository\n  igc tool-config [name]  Create the config map and secret for a tool configured\n                          in the environment\n  igc vlan                Print out the vlan values\n  igc yq <command>        lightweight yaml command-line processor that addresses\n                          deficiencies with the existing `yq` command\n\nOptions:\n  --version  Show version number                                       [boolean]\n  --help     Show help                                                 [boolean]\n```\n\nAs of v0.5.1, the <Globals name=\"igccli\" /> will now install the commands as plugins to the `kubectl` and `oc` CLIs. \nFor example, all of the following are equivalent:\n\n```bash\nigc pipeline\nkubectl pipeline\noc pipeline\n```\n\n### Prerequisite tools\n\n<InlineNotification>\n\nSome of the commands provided by the <Globals name=\"igccli\" /> orchestrate interactions between other CLIs. To get \nstarted please install the [prerequisite tools](/getting-started/prereqs), in particular:\n- The <Globals name=\"kube\" /> CLI\n- The <Globals name=\"ocp\" /> CLI\n- The <Globals name=\"ic\" /> CLI - used to interact with IBM Cloud vlans (not needed if tools will not run on IBM Cloud)\n\n</InlineNotification>\n\n### Log into your cluster\n\nMost all of the commands provided by the <Globals name=\"igccli\" /> interact with a cluster. It probably comes as no \nsurprise then that you should be logged into the prior to running the commands.\n\n<Accordion>\n\n<AccordionItem title=\"OpenShift\" open=\"true\">\n\n```bash\noc login --server=<url> --token=<apikey>\n```\n</AccordionItem>\n\n<AccordionItem title=\"Kubernetes\">\n\n```bash\nibmcloud ks cluster config --cluster <CLUSTER>\n```\n\n</AccordionItem>\n\n\n\n</Accordion>\n\n### Log into your IBM Cloud account\n\nThe `vlan` command provided by the <Globals name=\"igccli\" /> interacts with your IBM Cloud account to\nget the VLAN information needed to create a cluster. The command assumes you have already logged into\nyour account prior to running the command.\n\n- Log into your <Globals name=\"ic\" /> account with the correct region and resource group:\n\n    ```bash\n    ibmcloud login -a cloud.ibm.com -r <region> -g <resource group>\n    ```\n\n## Available commands\n\n### dashboard\n\nOpens the [Developer Dashboard](/getting-started/dashboard) in the default browser. If a default browser has not been \nconfigured, then the URL to the Dashboard will be printed out.\n\nThe dashboard displays the <Globals name=\"shortName\" /> tools configured within the cluster along with links to\nactivation content and links to Starter Kits to start a project quickly.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace where the dashboard has been deployed; the default is `tools`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc dashboard\n```\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands would have the same result on OpenShift:\n\n```shell script\nHOST=$(oc get routes/dashboard -n tools -o jsonpath='{.spec.host}')\nopen \"https://$HOST\"\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands would have the same result on Kubernetes:\n\n```shell script\nHOST=$(kubectl get ingress/developer-dashboard -n tools -o jsonpath='{.spec.rules[0].host}')\nopen \"https://$HOST\"\n```\n\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [credentials](#credentials): shows information about the same tools shown in the dashboard from the \ncommand-line\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### console\n\nOpens the *IKS or OpenShift admin console* in the default browser. If a default browser has not been \nconfigured, then the URL to the console will be printed out.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc console\n```\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands would have the same result on OpenShift:\n\n```shell script\nHOST=$(oc get routes/console -n openshift-console -o jsonpath='{.spec.host}')\nopen \"https://$HOST\"\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands would have the same result on Kubernetes:\n\n```shell script\nREGION=\"...\"\nCLUSTER_NAME=\"...\"\nCLUSTER_ID=$(ibmcloud ks cluster get --cluster ${CLUSTER_NAME} | grep -E \"^ID\" | sed -E \"s/ID: +([^ ]+)/\\\\1/g\")\nopen \"https://${REGION}.containers.cloud.ibm.com/kubeproxy/clusters/${CLUSTER_ID}/service/#/overview?namespace=default\"\n```\n\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [credentials](#credentials): shows information about the same tools shown in the dashboard from the \ncommand-line\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### credentials\n\nLists the endpoints, user names, and passwords for the tools configured in the environment. This is the easiest way to\nget the login credentials for each of the installed tools. Ideally all of the tools would be accessible via SSO at which\npoint this command will be obsolete.\n\nThe command works by reading information available in the cluster. When each tool is installed by the toolkit, a \n`config map` and `secret` are created to store the url and credential for the tool. That information is used in a \nnumber of different ways within the environment:\n\n- Provide configuration information to the pipelines\n- Populate the tiles on the [Developer Dashboard](/getting-started/dashboard)\n- Populate the results of the `credentials` command\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace where the tools have been deployed; the default is `tools`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```shell script\nigc credentials\n```\n\nThe credential output is JSON format like this\n\n```shell script\nCredentials:  {\n  argocd: {\n    user: 'admin',\n    password: '12345678',\n    url: 'https://argocd-tools.mycluster.us-east.containers.appdomain.cloud'\n  },\n  . . .\n  dashboard: {\n    url: 'https://dashboard-tools.mycluster.us-east.containers.appdomain.cloud'\n  },\n  . . .\n}\n```\n\n</Tab>\n<Tab label=\"OpenShift or Kubernetes\">\n\nThe following commands have the same result (note the dependency on `jq`):\n\n```shell script\n# config maps\nkubectl get configmap -n tools -l grouping=garage-cloud-native-toolkit -o json | \\\n  jq '[.items[] | select(.metadata.name != \"ibmcloud-config\").data]'\n\n# secrets\nkubectl get secret -n tools -l grouping=garage-cloud-native-toolkit -o json | \\\n  jq '[.items[] | select(.metadata.name != \"ibmcloud-apikey\").data | with_entries(.value |= @base64d)]'\n```\n</Tab>\n</Tabs>\n\n**Related commands**\n\n- [dashboard](#dashboard): displays the url of the Developer Dashboard and launches the default browser\n- [tool-config](#tool-config): allows configuration for additional tools to be added to the cluster, making them\navailable to the dashboard and `credentials` command   \n\n### endpoints\n\nLists the ingress and/or route URLs for the applications in a given namespace. An attempt will be made to get the \nnamespace from the current context if one is not provided as an argument. Results of the command are provided in an \ninteractive menu. If one of the endpoints is selected, it will display the URL and launch it in the default browser. \nSelecting `Exit` will print the full list of endpoints and exit.\n\nThis command requires that the login context for the cluster has already been established.\n\n**Command flags**\n- `-n`: the namespace from which the endpoints will be read; the value will be read from the current context if not \nprovided\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe command is used in the following way:\n\n```bash\nigc endpoints\n```\n\n</Tab>\n<Tab label=\"OpenShift\">\n\nThe following commands list the route and ingress endpoints:\n\n```shell script\n# routes\nkubectl get route -n tools\n\n# ingress\nkubectl get ingress -n tools\n```\n</Tab>\n<Tab label=\"Kubernetes\">\n\nThe following commands list the ingress endpoints:\n\n```shell script\nkubectl get ingress -n tools\n```\n</Tab>\n</Tabs>\n\n### sync (formerly namespace)\n\nCreates a Kubernetes namespace or OpenShift project (if it doesn't already exist) and sets it up so that the namespace\ncan be used as a target for application deployments and/or to host the <Globals name=\"env\" />. The command performs two\nmajor functions - 1) set up a service account in the namespace with the pull secret(s) for the IBM Container Registry \nand 2) synchronize the `ConfigMaps` and `Secrets` from a template namespace to create a \"development\" namespace. After\nthe command has run successfully it will set the provided namespace in the current context \n(e.g. equivalent to `oc project X`)\n\nThe pull secret(s) are required in order for pods to pull images that are stored in the IBM Container Registry.\nWhen the cluster is created in IBM Cloud, a pull secret is provided in the `default` namespace. In order for a \npod in another namespace to use it, the secret must first be copied into the namespace. After that, the pod either \nneeds to reference the pull secret directly or the service account used by the resource needs to have a reference to\nthe secret. The CLI copies the pull secret over and adds it to the service account so the pod can take either\napproach.\n\nThe other function this command performs is to copy relevant `ConfigMaps` and `Secrets` into the namespace that are\nneeded for development activities. Managing resources across namespaces (particularly `ConfigMaps` and `Secrets`) is a \ncommon challenge in Kubernetes environments. We have provided the command at this time to simplify the steps required \nto get everything ready. Ultimately, this problem seems like an ideal one for an Operator to solve and when one is \navailable (either from the Toolkit or elsewhere) this command will be retired or transitioned.\n\nThere are two different types of namespaces that the command will set up:\n\n- \"release\" namespace where applications can be deployed (e.g. test, staging)\n\n-OR-\n\n- \"development\" namespace where DevOps pipelines can be run and where application components can be deployed \n(e.g. dev)\n\nBoth \"release\" and \"development\" namespaces will have the pull secret(s) created. However, only the \"development\"\nnamespace will also have the `ConfigMaps` and `Secrets` copied over.\n\n**Command flags**\n- `-t`: the template namespace that will be the source of the `config maps` and `secrets`; the default is `tools`\n- `-z`: the name of the service account; the default is `default`\n- `--dev`: flag indicating the namespace should be set for development\n- `--verbose`: flag indicating that the console output should persist on the screen\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nCreate a `test` namespace\n\n```shell script\nigc sync test\n```\n\nCreate a `dev` namespace for development\n\n```shell script\nigc sync dev --dev\n```\n</Tab>\n<Tab label=\"Manual pull secret setup\">\n\nThe following commands will copy the pull secret(s) from the `default` namespace and add them to the service account:\n\n```shell script\nexport NAMESPACE=\"NAMESPACE\"\nexport SERVICE_ACCOUNT=\"default\"\n\nif [[ $(kubectl get secrets -n \"${NAMESPACE}\" -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | grep icr | wc -l | xargs) -eq 0 ]]; then\n    echo \"*** Copying pull secrets from default namespace to ${NAMESPACE} namespace\"\n\n    kubectl get secrets -n default | grep icr | sed \"s/\\([A-Za-z-]*\\) *.*/\\1/g\" | while read default_secret; do\n        kubectl get secret ${default_secret} -n default -o yaml --export | sed \"s/name: default-/name: /g\" | kubectl -n ${NAMESPACE} create -f -\n    done\nelse\n    echo \"*** Pull secrets already exist on ${NAMESPACE} namespace\"\nfi\n\n\nEXISTING_SECRETS=$(kubectl get serviceaccount/${SERVICE_ACCOUNT} -n \"${NAMESPACE}\" -o json  | tr '\\n' ' ' | sed -E \"s/.*imagePullSecrets.: \\[([^]]*)\\].*/\\1/g\" | grep icr | wc -l | xargs)\nif [[ ${EXISTING_SECRETS} -eq 0 ]]; then\n    echo \"*** Adding secrets to serviceaccount/${SERVICE_ACCOUNT} in ${NAMESPACE} namespace\"\n\n    PULL_SECRETS=$(kubectl get secrets -n \"${NAMESPACE}\" -o jsonpath='{ range .items[*] }{ \"{\\\"name\\\": \\\"\"}{ .metadata.name }{ \"\\\"}\\n\" }{ end }' | grep icr | grep -v \"${NAMESPACE}\" | paste -sd \",\" -)\n    kubectl patch -n \"${NAMESPACE}\" serviceaccount/${SERVICE_ACCOUNT} -p \"{\\\"imagePullSecrets\\\": [${PULL_SECRETS}]}\"\nelse\n    echo \"*** Pull secrets already applied to serviceaccount/${SERVICE_ACCOUNT} in ${NAMESPACE} namespace\"\nfi\n```\n</Tab>\n<Tab label=\"Manual ConfigMap and Secret setup\">\n\nThe following steps will copy the `ConfigMaps` and `Secrets` from a template namespace to a target namespace:\n\n```shell script\n  export TEMPLATE_NAMESPACE=\"tools\"\n  export NAMESPACE=\"NAMESPACE\"\n\n  kubectl get configmap -l grouping=garage-cloud-native-toolkit -n ${TEMPLATE_NAMESPACE} -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | \\\n    while read cm; do\n      kubectl get configmap ${cm} --namespace ${TEMPLATE_NAMESPACE} --export -o yaml | \\\n        kubectl apply --namespace $NAMESPACE -f -\n    done\n\n  kubectl get secret -l grouping=garage-cloud-native-toolkit -n ${TEMPLATE_NAMESPACE} -o jsonpath='{ range .items[*] }{ .metadata.name }{ \"\\n\" }{ end }' | \\\n    while read cm; do\n      kubectl get secret ${cm} --namespace ${TEMPLATE_NAMESPACE} --export -o yaml | \\\n        kubectl apply --namespace $NAMESPACE -f -\n    done\n\n```\n</Tab>\n</Tabs>\n\n### pipeline\n\nConnects a branch in a Git repo to a either a Jenkins or Tekton CI pipeline in the <Globals name=\"env\" /> and triggers \nan initial build. A webhook is also created so that when a new commit is added to the branch, the pipeline is triggered\nto start the process to rebuild and redeploy the app using the new code. The Git repo needs to be hosted using a site \nthat supports triggers such as GitHub or GitLab. \n\nThis command requires that the terminal is already logged in to the cluster. It also requires that the terminal's \ncurrent directory is the repository directory for your local copy of the Git repo. The command uses the local Git \nrepo's configuration to find the server copy.\n\nIf Jenkins or Tekton are not specified when the command is invoked then you will be prompted for which CI tool to use. \nThe command will also prompt for the username and personal access token to access the Git repository, unless those are \nprovided as command-line parameters. It will also prompt you for the branch to use to trigger builds; the default \nis the current branch.\n\n**Command flags**\n- `-n`: the deployment namespace; if not provided the namespace from the current context will be used\n- `-u`: the username for accessing the Git repo\n- `-p`: the personal access token for accessing the Git repo\n- `--jenkins`: deploy using a Jenkins pipeline\n- `--tekton`: deploy using a Tekton pipeline\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\nCreate a Jenkins pipeline in the `dev` namespace and prompt for the Git credentials\n\n```shell script\nigc pipeline --jenkins\n```\n\nCreate a Tekton pipeline in the `my-dev` namespace, using the Git credentials `gituser` and `gitpat`\n\n```shell script\nigc pipeline -n my-dev -u gituser -p gitpat --tekton\n```\n</Tab>\n<Tab label=\"Manual Steps for Tekton\">\n\nThe following is the list of steps required to manually configure a **Tekton** \npipeline with your development cluster.\n<br></br>\n\n\n- Configure the service account `pipeline` if it doesn't exist, on OpenShift 4 the operator takes care of this you can skip.\n  ```\n  oc create serviceaccount pipeline\n  oc adm policy add-scc-to-user privileged -z pipeline\n  oc adm policy add-role-to-user edit -z pipeline\n  ```\n- Clone the tasks from the `tools` namespace into the `new-namespace`\n  ```\n  kubectl get tasks --export -o yaml -n tools  | sed s/\"namespace: tools/namespace: $(oc project -q)\"/ | kubectl apply -f -\n  ```\n- Clone the pipelines from the `tools` namespace into the `new-namespace`\n  ```\n  kubectl get pipelines --export -o yaml -n tools  | sed s/\"namespace: tools/namespace: $(oc project -q)\"/ | kubectl apply -f -\n  ```\n\n### Pipeline Resource\n\n- Create a Pipeline resource for the git repository, replace with the correct github url for your repository\n  Use the `tkn` CLI to create `git` resource input the github repo url for `url` and branch for `revision`\n  ```\n  tkn resource create\n  ```\n  Here is the an example of the cli\n  ```\n  tkn resource create\n  ? Enter a name for a pipeline resource : nodejs-typescript-git\n  ? Select a resource type to create : git\n  ? Enter a value for url :  https://github.com/{user or org}/{app}\n  ? Enter a value for revision :  master\n  New git resource \"nodejs-typescript-git\" has been created\n  ```\n- Create a Pipeline resource for the docker image registry, you can use the internal registry in OpenShift or use an external registry like IBM Container Registry (credentials need setup)\n  Use the `tkn` CLI to create `image` resource\n  ```\n  tkn resource create\n  ```\n  Select `image` for type.\n\n  Enter the corresponding `url` for container registry, use the new-namespace} in the url\n\n  For OCP 3 internal registry use `docker-registry.default.svc:5000/{new-namespace}/node-typescript:latest`\n\n  For OCP 4 or CRC internal registry use `image-registry.openshift-image-registry.svc:5000/{new-namespace}/node-typescript:latest`\n\n  For external registry like IBM Container registry based on region use `us.icr.io/{namespace}/node-typescript:latest` use an existing namespace in your IBM Cloud\n  ```\n  tkn resource create\n  ? Enter a name for a pipeline resource : nodejs-typescript-image\n  ? Select a resource type to create : image\n  ? Enter a value for url :  docker-registry.default.svc:5000/dev/node-typescript:latest\n  ? Enter a value for digest :\n  New image resource \"nodejs-typescript-image\" has been created\n  ```\n- Select the pipeline, to show the available pipeline run\n  ```\n  tkn pipeline ls\n  NAME              AGE              LAST RUN   STARTED   DURATION   STATUS\n  igc-java-gradle   33 minutes ago   ---        ---       ---        ---\n  igc-nodejs        33 minutes ago   ---        ---       ---        ---\n  ```\n  In this case use `igc-java-gradle` for java or `igc-nodejs` for nodejs.\n- Run the Pipeline using the `git` and `image` Pipeline resources.\n  Set the following environment variable for convienience:\n  ```\n  export PIPELINE=igc-nodejs\n  export GIT=nodejs-typescript-git\n  export IMAGE=nodejs-typescript-image\n  ```\n  Then run the `tkn pipeline start` with the input arguments using the service account `pipeline`\n  ```\n  tkn pipeline start \\\n  ${PIPELINE} \\\n  -r git-source=${GIT} \\\n  -r docker-image=${IMAGE} \\\n  -s pipeline\n  ```\n\n### Create a Git Webhook\n\n- Open the Tekton Dashboard from the main Tools Dashboard or the ICPA landing page.\n\n- Create a Webhook in the Tekton Dashboard\n    ![Webhook](/images/webhook.png)\n\n    - Click **Webhook** on the menu\n    - Click **Add Webhook** and enter the information for the webhook\n    - Name: **insert name**\n    - Repository UR: **template git repo url**\n    - Access Token: Create github access token with permission minimum write:repo_hook\n    - Namespace: **insert namespace**\n    - Pipeline: select **igc-java-gradle** or **igc-nodejs**\n    - Service Account: **pipeline**\n    - Docker Registry:\n        - For OCP 3 internal registry use `docker-registry.default.svc:5000/{new-namespace}`\n        - For OCP 4 or CRC internal registry use `image-registry.openshift-image-registry.svc:5000/{new-namespace}`\n        - For external registry like IBM Container registry based on region use `us.icr.io/{namespace}` use an existing namespace in your IBM Cloud. Make sure to configure docker credentials in the Tekton Dashboard using your IAM API Key and `iamapikey` for username in your namespace.\n\n- Check that Webhook is created on the Github repository (Settings-Webhooks)\n\n- Make a change to the git repo and push the change to remote git repository or click on **Pipelines**\nand manually kick of a pipeline build\n\n</Tab>\n<Tab label=\"Manual steps for Jenkins on OpenShift\">\n\n### 1. Provision Jenkins ephemeral\n\nJenkins ephemeral provides a kubernetes native version of Jenkins that dynamically provisions build agents on-demand. \nIt's _ephemeral_ meaning it doesn't allocate any persistent storage in the cluster.\n\n1. Set the project/namespace\n\n```shell script\noc project {NAMESPACE}\n```\n\nwhere:\n- `{NAMESPACE}` is the development namespace where the pipelines will run\n\n2. Run the following command to provision the Jenkins instance in your namespace\n\n```shell script\noc new-app jenkins-ephemeral\n```\n\n3. Open the OpenShift console as described in the login steps above\n\n4. Select `Workloads -> Pods` from the left-hand menu\n\n5. At the top of the page select your project/namespace from the drop-down list to see the Jenkins instance running\n\n### 2. Give the `jenkins` service account `privileged` access\n\nAll of the <Globals name=\"shortName\"/> pipelines use `buildah` to build and push the container image to the registry. \nUnfortunately, the `buildah` container must run as root. By default, OpenShift does not allow containers to run as the \nroot user and special permission is required for the pipeline to run.\n\nWith the Jenkins build engine, all the build processes run as the `jenkins` service account. In order for the pipeline \ncontainer to run as root on OpenShift we will need to give the `privileged` security context constraint (scc) to \n`jenkins` service account with the following command:\n\n```shell script\noc project {NAMESPACE}\noc adm policy add-scc-to-user privileged -z jenkins\n```\n\nwhere:\n - `{NAMESPACE}` should be the name you claimed in the box note prefixed to `-dev` (e.g. user01-dev)\n\n### 3. Create a secret with git credentials\n\nIn order for Jenkins to have access to the git repository, particularly if it is a private repository, a Kubernetes \nsecret needs to be added that contains the git credentials.\n\n1. Create a personal access token (if you don't already have one) using the prereq instructions - \nhttps://cloudnativetoolkit.dev/getting-started/prereqs#configure-github-personal-access-token\n\n2. Copy the following into a file called `gitsecret.yaml` and update the {Git-Username}, and {Git-PAT}\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  annotations:\n    build.openshift.io/source-secret-match-uri-1: https://github.com/*\n  labels:\n    jenkins.io/credentials-type: usernamePassword\n  name: git-credentials\ntype: kubernetes.io/basic-auth\nstringData:\n  username: {Git-Username}\n  password: {Git-PAT}\n```\n\nwhere:\n - `Git-Username` is the username that has access to the git repo\n - `Git-PAT` is the personal access token of the git user\n\n2. After logging into the cluster, create the secret by running the following:\n\n```shell script\noc project {NAMESPACE}\noc create -f gitsecret.yaml\n```\n\nwhere:\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n### 3. Create the build config\n\nOn OpenShift 4.3, Jenkins is built into the OpenShift console and the build pipelines can be managed using Kubernetes \ncustom resources. The following steps will create one by hand to create the build pipeline for the new application.\n\n1. Copy the following into a file called `buildconfig.yaml` and update the {Name}, {Secret}, {Git-Repo-URL}, \nand {Namespace}\n\n```yaml\napiVersion: v1\nkind: BuildConfig\nmetadata:\n  name: {Name}\nspec:\n  triggers:\n  - type: GitHub\n    github:\n      secret: my-secret-value\n  source:\n    git:\n      uri: {Git-Repo-URL}\n      ref: master\n  strategy:\n    jenkinsPipelineStrategy:\n      jenkinsfilePath: Jenkinsfile\n      env:\n      - name: CLOUD_NAME\n        value: openshift\n      - name: NAMESPACE\n        value: {NAMESPACE}\n```\n\nwhere:\n - `Name` is in the name of your pipeline \n - `Git-Repo-URL` is the https url to the git repository\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n2. Assuming you are still logged into the cluster, create the buildconfig resource in the cluster\n\n```shell script\noc project {NAMESPACE}\noc create -f buildconfig.yaml\n```\n\nwhere:\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\n### 4. View the pipeline in the OpenShift console\n\n1. Open the OpenShift console for the cluster\n2. Select Builds -> Build Config\n3. Select your project/namespace (i.e. `{NAMESPACE}`) from the top\n4. The build pipeline that was created in the previous step should appear\n5. Manually trigger the pipeline by selecting `Start Build` the menu button on the right side of the row\n\n### 5. Create the webhook\n\n1. Run the following to get the webhook details from the build config \n\n```\noc project {NAMESPACE}\noc describe bc {Name}\n```\n\nwhere:\n - `{Name}` is the name used in the previous step for the build config\n - `{NAMESPACE}` is the development namespace where the pipelines will run\n\nThe webhook url will have a structure similar to:\n\n`http://{openshift_api_host:port}/oapi/v1/namespaces/{namespace}/buildconfigs/{name}/webhooks/{secret}/generic`\n\nIn this case `{secret}` will be `my-secret-value`\n\n2. Open a browser to the GitHub repo deployed in the previous step in the build config\n\n3. Select `Settings` then `Webhooks`. Press `Add webhook`\n\n4. Paste the webhook url from the previous step into the `Payload url`\n\n5. Set the content-type to `application/json` and leave the rest of the values as the defaults\n\n6. Press `Add webhook` to create the webhook\n\n7. Press the button to test the webhook to ensure that everything was done properly\n\n8. Go back to your project code and push a change to one of the files\n   \n9. Go to the Build pipeline page in the OpenShift console to see that the build was triggered\n\n</Tab>\n<Tab label=\"Manual steps for Jenkins on Kubernetes\">\n\nTBD\n\n</Tab>\n</Tabs>\n\n### enable\n\nAdds DevOps artifacts to a Git repo that the <Globals name=\"env\" /> uses to deploy the app. The command displays a \nlist of available pipelines and applies the one you select to your code repo. The DevOps files added to your repo\n include (but are not limited to):\n\n- Helm chart\n- Jenkinsfile\n\nThis command DOES NOT require that the terminal is already logged in to an IBM Cloud account nor the cluster. It DOES\nrequire that the terminal's current directory is the repository directory for your local copy of the Git repo.\n\nThe command will add files to the local repo. You should commit these new files and push them to the server repo. \nThen run `igc pipeline` to connect your repo to a pipeline in the environment.\n\n**Command flags**\n- `--repo`: the set of pipelines to choose from; the default is https://github.com/ibm-garage-cloud/garage-pipelines\n- `-p`: the name of the pipeline that should be installed; if not provided then you will be prompted\n- `-b`: the branch from which the pipeline should be installed; the default is `stable` \n- `r`: the version number of the pipeline that should be installed; the default is `latest`\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\n1. Before running the command, make sure you have a clean repository with no unstaged changes. Either commit any\nchanges or stash them temporarily with `git stash`. It is particularly important that any changes to the pipeline be\ndealt with.\n\n2. Apply the pipeline updates using the CLI command\n\n```shell script\nigc enable\n```\n\n3. Review the changes using `git diff` and revert any application-specific changes that should remain (e.g. \ncustomization to the Jenkins pipeline in the `Jenkinsfile`, specific values added to `values.yaml`, customizations\nto the templates in the `helm chart`)\n\n4. Commit the changes when you are happy with them\n\n</Tab>\n<Tab label=\"Manual steps\">\n\nThe follow provides the manual steps equivalent to the `igc enable` command:\n\n1. Before updating the pipelines, make sure you have a clean repository with no unstaged changes. Either commit any\nchanges or stash them temporarily with `git stash`. It is particularly important that any changes to the pipeline be\ndealt with.\n\n2. Download the `index.yaml` file containing the available pipeline versions\n\n    ```shell script\n    curl -O https://ibm-garage-cloud.github.io/garage-pipelines/index.yaml\n    ```\n\n3. Look through the `index.yaml` file to identify the url for the desired pipeline branch and version\n\n4. With the PIPELINE_URL from the previous step, run the following to download the pipeline tar-ball\n\n    ```shell script\n    curl -O ${PIPELINE_URL}\n    ```\n\n5. Extract the tar-ball into your repository directory. You will be prompted to overwrite files. Overwrite as\nappropriate\n\n    ```shell script\n    tar xzf ${PIPELINE_FILE}\n    ```\n\n6. Review the changes using `git diff` and revert any application-specific changes that should remain (e.g. \ncustomization to the Jenkins pipeline in the `Jenkinsfile`, specific values added to `values.yaml`, customizations\nto the templates in the `helm chart`)\n\n7. Commit the changes when you are happy with them\n\n</Tab>\n</Tabs>\n\n### tool-config\n\nConfigures a new tool in the environment. After deploying the tool, use this command to add the tool to the list of \ncredentials so that it will be displayed in the dashboard.\n\n**Command flags**\n- The name for the tool\n- `-n`: the tools namespace; the default is `tools`\n- `--url`: the endpoint for accessing the tool, usually its dashboard\n- `--username`: (optional) the user name for logging into to tool\n- `--password`: (optional) the password for logging into to tool\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nThe following gives an example of using the `tool-config` command to set up a tool named `my-tool` with its \ndashboard's endpoint and credentials\n\n```shell script\nigc tool-config my-tool \\\n  --url https://mytool-dashboard.mycluster.us-east.containers.appdomain.cloud \\\n  --username admin \\\n  --password password\n```\n\n</Tab>\n<Tab label=\"Manual install with helm\">\n\nThe following gives an example of using helm directly to do the equivalent (using helm 3):\n\n```shell script\nhelm install my-tool tool-config \\\n  --repo https://ibm-garage-cloud.github.io/toolkit-charts/ \\\n  --set url=https://mytool-dashboard.mycluster.us-east.containers.appdomain.cloud \\\n  --set username=admin \\\n  --set password=password\n```\n</Tab>\n</Tabs>\n\n### vlan\n\nLists the VLANs for a particular IBM Cloud region. This information is useful for preparing Terraform cluster creation \nsteps. The command reads all the data centers in the region and allows you to select the appropriate data center for\nthe vlan. \n\nThis command requires that the terminal is already logged in to the cloud region. It does NOT need to be logged in to a cluster.\n\n**Usage**\n\n<Tabs>\n<Tab label=\"CLI\">\n\nList a pair of public/private VLANs for a new environment to use\n\n```shell script\nigc vlan\n```\n\n</Tab>\n<Tab label=\"Manual steps\">\n\n1. List the zones for the region\n    ```shell script\n    ibmcloud ks zones --region-only --provider classic\n    ```\n\n2. Select the desired zone from the listing provided by the previous command and run the following to list the\nvlans for that zone\n\n    ```shell script\n    ibmcloud ks vlans --zone ${zone}\n    ```\n\n</Tab>\n</Tabs>\n","fileAbsolutePath":"/home/runner/work/ibm-garage-developer-guide/ibm-garage-developer-guide/src/pages/getting-started/cli/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","227138135","227138135","2456312558","2746626797","2746626797","2982904675","3018647132","3018647132","3906363820","3906363820","768070550"]}