{"componentChunkName":"component---src-pages-getting-started-day-2-index-mdx","path":"/getting-started-day-2/","result":{"pageContext":{"frontmatter":{"title":"Overview - Day 2"},"relativePagePath":"/getting-started-day-2/index.mdx","titleType":"page","MdxNode":{"id":"8f861ff8-768e-570d-ae15-398702097189","children":[],"parent":"94bc6d32-0003-5ec0-8e6e-46a929a41614","internal":{"content":"---\ntitle: Overview - Day 2\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n## **Getting Started**\n\nDay 2 of the software development lifecycle is all about deploying and managing the applications that have been developed. These \nactivities are primarily the domain of SREs and Sys Admins but it is important that Developers understand and utilize these\nconcepts and tools during their Day 1 activities to help support the application components through the life-cycle.\n\n<br></br>\n\n## **Day 2 Concepts/Tools Explained**\n\n### *Continuous Delivery*\n\nIn IBM Garage Method, one of the **Develop** practices is [continuous delivery](https://www.ibm.com/garage/method/practices/deliver/practice_continuous_delivery/). \nA preferred model for implementing continuous delivery is GitOps, where the desired state of the operational environment\nis defined in a source control repository (namely Git). \n\n### What is Continuous Delivery?\n\nContinuous delivery is the DevOps approach of frequently making new versions of an application's components available for\ndeployment to a runtime environment. The process involves automation of the build and validation process and concludes \nwith a new version of the application that is available for promotion to another environment.\n\nContinuous delivery is closely related to continuous deployment. The distinction is:\n- Continuous delivery deploys an application when a user manually triggers deployment\n- Continuous deployment deploys an application automatically when it is ready\n\nTypically, continuous deployment is an evolution of a continuous delivery process. An application is ready for \ndeployment when it passes a set of tests that prove it doesn't contain any significant problems. Once these tests have been \nautomated in a way that reliably verifies the application components then the deployment can be automated. Additionally,\nfor continuous delivery it important to employ other best practices around moving and managing changes in an environment: \nblue-green deployments, shadow deployments, and feature toggles to name a few. Until these practices are in place and \nverified, it is best to stick with continuous delivery. \n\nAs with most cloud-native practices, the move from continuous deployment to continuous delivery would not be done in\na \"big bang\" but incrementally and as different application components are ready. \n\n### CI/CD integration\n\nFor the full end-to-end build and delivery process, both the CI and CD pipelines are used. When working in\na containerized environment such as <Globals name=\"kube\" /> or <Globals name=\"ocp\" />, the responsibilities between the \ntwo processes are clearly defined:\n\n- The **CI pipeline** is responsible for building validating and packaging the \"raw materials\" (source code, deployment \nconfiguration, etc) into versioned, deployable artifacts (container images, helm charts, published artifacts, etc)\n- The **CD pipeline** is responsible for applying the deployable artifacts into a particular target environment\n\n![CI/CD end-to-end](./images/CI_CD-pipelines.png)\n\n1. A change made to one of the source repositories triggers the CI process.\n\n2. The CI process builds, validates, and packages those changes into deployable artifacts that are stored in the image\nregistry and artifact repository(ies).\n\n3. The last step of the CI process updates the GitOps repository with information about the updated artifacts. \n\n    At a minimum this step stores updates the version number to the newly released versions of the artifacts but depending on the environment this step might also update the deployment configuration.\n    \n    <InlineNotification>\n    \n    It is also possible to trigger a process when a new image is available in the image registry or a new artifact is available\n    to the artifact management system. \n    \n    In this case, the CI process could be split into two parts: **1)** create the \n    container image and artifacts, and **2)** update the GitOps repo with the available artifacts.\n    \n    </InlineNotification>\n\n4. Changes to the GitOps repository trigger the CD pipeline to run\n\n5. In the CD pipeline, the configuration describing the desired state as defined in the GitOps repository is reconciled \nwith the actual state of the environment and resources are created, updated, or destroyed as appropriate.\n\n### Tools to support Continuous Delivery\n\nThe practice of (CD) can be accomplished in different ways and with different tools. It is possible and\ncertainly valid to use the same tool for both CI and CD (e.g. Tekton or Jenkins) with caution you enforce a clear separation\nbetween the two processes. Typically, that would result in two distinct pipelines to respond to changes that happen\nwithin the two different Git repos - source repo and gitops repo.\n\nAnother class of tools is available that are particularly suited for Continuous Delivery and GitOps. The following is by no\nmeans an exhaustive list but it does provide some of the common tools used for CD in a cloud-native environment:\n\n- [ArgoCD](/tools/argocd)\n- Flux\n- [IBM Multicloud Manager](https://www.ibm.com/cloud/cloud-pak-for-management)\n\n\n---\n\n### *Secret Management*\n\nDeploying an application into containers involves both the application logic and the associated configuration. The application\nlogic is packaged into a container image so that it can be deployed but in order to make the container image portable\nacross different environments, the application configuration should be managed separately and applied to the application\ncontainer image at deployment time.\n\nFortunately, container platforms lik <Globals name=\"ocp\" /> and <Globals name=\"kube\" /> provides a mechanism to easily \nprovide the configuration at deployment time: ConfigMaps and Secrets. Both ConfigMaps and Secrets work in the same way to \nrepresent information in key value pairs and allow that information to be attached to a running container in a number of \ndifferent ways. Unlike ConfigMaps, Secrets are intended to hold sensitive information (like passwords) and have additional access control facilities to limit who can read and use that information.\n\nWith a [GitOps](/getting-started-day-0#gitops) approach to [continuous delivery](#continuous-delivery),\nthe application container image and the associated configuration are represented in the Git repository together. When\nthe desired state defined in Git is applied to an environment, the relevant <Globals name=\"kube\" /> resources like Deployments,\nConfigMaps, and Secrets are generated from the provided Git configuration.\n\nA common issue when doing GitOps is how to handle sensitive information that should not be stored in the Git repository \n(e.g. passwords, keys, etc). There are two different approaches to how to handle this issue:\n\n1. Inject the values from another source into kubernetes Secret(s) at deployment time\n2. Inject the values from another source in the pod at startup time via an InitContainer\n\nThe \"other source\" in this case would be a key management system that centralizes the storage and management of sensitive \ninformation. There are a number of key management systems available to manage the secret values:\n\n- [Key Protect](/tools/secret-management-with-key-protect)\n- Hyper Protect\n- Hashicorp Vault\n\n### Use the key management system at deployment time\n\n[CD with ArgoCD](/tools/argocd) covers how to use ArgoCD to do GitOps, including how to manage sensitive information in a \nkey management system.\n\n### Use the key management system at pod startup time\n\nComing soon\n\n\n---\n\n### *Monitoring*\n\nIn IBM Garage Method, one of the Operate practices is to [automate application monitoring](https://www.ibm.com/garage/method/practices/manage/practice_automated_monitoring/). Sysdig automates application monitoring, enabling an operator to view stats and collect metrics about a Kubernetes cluster and its deployments. The <Globals name=\"env\" /> includes an IBM Cloud Monitoring with Sysdig service instance configured with a Sysdig agent installed in the environment's cluster. Simply by deploying your application into the <Globals name=\"env\" />, Sysdig monitors it, just open the Sysdig web UI from the IBM Cloud dashboard to browse your application's status.\n\n--- \n\n### *Log Management*\n\nIn IBM Garage Method, one of the Operate practices is to [automate application monitoring](https://www.ibm.com/garage/method/practices/manage/practice_automated_monitoring/), including logging. Imagine your application isn't working right in production even though the environment is fine. What information would you want in your logs to help you figure out what's wrong with your application? Build logging messages for that information into your application.\n\nGiven that your application is logging, as are lots of other applications and services in your cloud environment, these logs need to be managed and made accessible. LogDNA adds log management capabilities to a Kubernetes cluster and its deployments. The <Globals name=\"env\" /> includes an IBM Log Analysis with LogDNA service instance configured with a LogDNA agent installed in the environment's cluster. Simply by deploying your application into the <Globals name=\"env\" />, LogDNA collects the logs, just open the LogDNA web UI from the IBM Cloud dashboard to browse your application's logs.\n","type":"Mdx","contentDigest":"655dacb95bfc5526f47f771883df02c9","counter":909,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Overview - Day 2"},"exports":{},"rawBody":"---\ntitle: Overview - Day 2\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n## **Getting Started**\n\nDay 2 of the software development lifecycle is all about deploying and managing the applications that have been developed. These \nactivities are primarily the domain of SREs and Sys Admins but it is important that Developers understand and utilize these\nconcepts and tools during their Day 1 activities to help support the application components through the life-cycle.\n\n<br></br>\n\n## **Day 2 Concepts/Tools Explained**\n\n### *Continuous Delivery*\n\nIn IBM Garage Method, one of the **Develop** practices is [continuous delivery](https://www.ibm.com/garage/method/practices/deliver/practice_continuous_delivery/). \nA preferred model for implementing continuous delivery is GitOps, where the desired state of the operational environment\nis defined in a source control repository (namely Git). \n\n### What is Continuous Delivery?\n\nContinuous delivery is the DevOps approach of frequently making new versions of an application's components available for\ndeployment to a runtime environment. The process involves automation of the build and validation process and concludes \nwith a new version of the application that is available for promotion to another environment.\n\nContinuous delivery is closely related to continuous deployment. The distinction is:\n- Continuous delivery deploys an application when a user manually triggers deployment\n- Continuous deployment deploys an application automatically when it is ready\n\nTypically, continuous deployment is an evolution of a continuous delivery process. An application is ready for \ndeployment when it passes a set of tests that prove it doesn't contain any significant problems. Once these tests have been \nautomated in a way that reliably verifies the application components then the deployment can be automated. Additionally,\nfor continuous delivery it important to employ other best practices around moving and managing changes in an environment: \nblue-green deployments, shadow deployments, and feature toggles to name a few. Until these practices are in place and \nverified, it is best to stick with continuous delivery. \n\nAs with most cloud-native practices, the move from continuous deployment to continuous delivery would not be done in\na \"big bang\" but incrementally and as different application components are ready. \n\n### CI/CD integration\n\nFor the full end-to-end build and delivery process, both the CI and CD pipelines are used. When working in\na containerized environment such as <Globals name=\"kube\" /> or <Globals name=\"ocp\" />, the responsibilities between the \ntwo processes are clearly defined:\n\n- The **CI pipeline** is responsible for building validating and packaging the \"raw materials\" (source code, deployment \nconfiguration, etc) into versioned, deployable artifacts (container images, helm charts, published artifacts, etc)\n- The **CD pipeline** is responsible for applying the deployable artifacts into a particular target environment\n\n![CI/CD end-to-end](./images/CI_CD-pipelines.png)\n\n1. A change made to one of the source repositories triggers the CI process.\n\n2. The CI process builds, validates, and packages those changes into deployable artifacts that are stored in the image\nregistry and artifact repository(ies).\n\n3. The last step of the CI process updates the GitOps repository with information about the updated artifacts. \n\n    At a minimum this step stores updates the version number to the newly released versions of the artifacts but depending on the environment this step might also update the deployment configuration.\n    \n    <InlineNotification>\n    \n    It is also possible to trigger a process when a new image is available in the image registry or a new artifact is available\n    to the artifact management system. \n    \n    In this case, the CI process could be split into two parts: **1)** create the \n    container image and artifacts, and **2)** update the GitOps repo with the available artifacts.\n    \n    </InlineNotification>\n\n4. Changes to the GitOps repository trigger the CD pipeline to run\n\n5. In the CD pipeline, the configuration describing the desired state as defined in the GitOps repository is reconciled \nwith the actual state of the environment and resources are created, updated, or destroyed as appropriate.\n\n### Tools to support Continuous Delivery\n\nThe practice of (CD) can be accomplished in different ways and with different tools. It is possible and\ncertainly valid to use the same tool for both CI and CD (e.g. Tekton or Jenkins) with caution you enforce a clear separation\nbetween the two processes. Typically, that would result in two distinct pipelines to respond to changes that happen\nwithin the two different Git repos - source repo and gitops repo.\n\nAnother class of tools is available that are particularly suited for Continuous Delivery and GitOps. The following is by no\nmeans an exhaustive list but it does provide some of the common tools used for CD in a cloud-native environment:\n\n- [ArgoCD](/tools/argocd)\n- Flux\n- [IBM Multicloud Manager](https://www.ibm.com/cloud/cloud-pak-for-management)\n\n\n---\n\n### *Secret Management*\n\nDeploying an application into containers involves both the application logic and the associated configuration. The application\nlogic is packaged into a container image so that it can be deployed but in order to make the container image portable\nacross different environments, the application configuration should be managed separately and applied to the application\ncontainer image at deployment time.\n\nFortunately, container platforms lik <Globals name=\"ocp\" /> and <Globals name=\"kube\" /> provides a mechanism to easily \nprovide the configuration at deployment time: ConfigMaps and Secrets. Both ConfigMaps and Secrets work in the same way to \nrepresent information in key value pairs and allow that information to be attached to a running container in a number of \ndifferent ways. Unlike ConfigMaps, Secrets are intended to hold sensitive information (like passwords) and have additional access control facilities to limit who can read and use that information.\n\nWith a [GitOps](/getting-started-day-0#gitops) approach to [continuous delivery](#continuous-delivery),\nthe application container image and the associated configuration are represented in the Git repository together. When\nthe desired state defined in Git is applied to an environment, the relevant <Globals name=\"kube\" /> resources like Deployments,\nConfigMaps, and Secrets are generated from the provided Git configuration.\n\nA common issue when doing GitOps is how to handle sensitive information that should not be stored in the Git repository \n(e.g. passwords, keys, etc). There are two different approaches to how to handle this issue:\n\n1. Inject the values from another source into kubernetes Secret(s) at deployment time\n2. Inject the values from another source in the pod at startup time via an InitContainer\n\nThe \"other source\" in this case would be a key management system that centralizes the storage and management of sensitive \ninformation. There are a number of key management systems available to manage the secret values:\n\n- [Key Protect](/tools/secret-management-with-key-protect)\n- Hyper Protect\n- Hashicorp Vault\n\n### Use the key management system at deployment time\n\n[CD with ArgoCD](/tools/argocd) covers how to use ArgoCD to do GitOps, including how to manage sensitive information in a \nkey management system.\n\n### Use the key management system at pod startup time\n\nComing soon\n\n\n---\n\n### *Monitoring*\n\nIn IBM Garage Method, one of the Operate practices is to [automate application monitoring](https://www.ibm.com/garage/method/practices/manage/practice_automated_monitoring/). Sysdig automates application monitoring, enabling an operator to view stats and collect metrics about a Kubernetes cluster and its deployments. The <Globals name=\"env\" /> includes an IBM Cloud Monitoring with Sysdig service instance configured with a Sysdig agent installed in the environment's cluster. Simply by deploying your application into the <Globals name=\"env\" />, Sysdig monitors it, just open the Sysdig web UI from the IBM Cloud dashboard to browse your application's status.\n\n--- \n\n### *Log Management*\n\nIn IBM Garage Method, one of the Operate practices is to [automate application monitoring](https://www.ibm.com/garage/method/practices/manage/practice_automated_monitoring/), including logging. Imagine your application isn't working right in production even though the environment is fine. What information would you want in your logs to help you figure out what's wrong with your application? Build logging messages for that information into your application.\n\nGiven that your application is logging, as are lots of other applications and services in your cloud environment, these logs need to be managed and made accessible. LogDNA adds log management capabilities to a Kubernetes cluster and its deployments. The <Globals name=\"env\" /> includes an IBM Log Analysis with LogDNA service instance configured with a LogDNA agent installed in the environment's cluster. Simply by deploying your application into the <Globals name=\"env\" />, LogDNA collects the logs, just open the LogDNA web UI from the IBM Cloud dashboard to browse your application's logs.\n","fileAbsolutePath":"/home/runner/work/ibm-garage-developer-guide/ibm-garage-developer-guide/src/pages/getting-started-day-2/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","3273249464","768070550"]}