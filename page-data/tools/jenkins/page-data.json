{"componentChunkName":"component---src-pages-tools-jenkins-index-mdx","path":"/tools/jenkins/","result":{"pageContext":{"frontmatter":{"title":"Continuous Integration with Jenkins"},"relativePagePath":"/tools/jenkins/index.mdx","titleType":"page","MdxNode":{"id":"7a04385b-bf96-5267-ab20-00e8aa39f486","children":[],"parent":"746c2616-d926-522b-b0a5-8953b4688914","internal":{"content":"---\ntitle: Continuous Integration with Jenkins\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nUse Jenkins to automate your continuous integration process\n\n</PageDescription>\n\n[Jenkins](https://jenkins.io/) is a self-contained, open source automation server that can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping manage continuous integration tasks for a wide range of software components.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins that supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code.\" The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) that in turn is checked into a project’s source control repository.\n\n### Pipelines\n\nPipelines offer a set of stages or steps that can be chained together to allow a level of software\nautomation. This automation can be tailored to the specific project requirements.\n\nYou can read more information about Jenkins Pipelines [here](https://jenkins.io/doc/book/pipeline/)\n\n### Stages\n\nPipelines are defined in a `Jenkinsfile` that sits in the root of your application code. It defines a number of stages. Each of the [<Globals name=\"templates\" />](/starterkits) includes a `Jenkinsfile` that offers a number of stages. The stages have been configured to complete the build, test, package, and deploy of the application code. Each stage can use the defined defined `secrets` and `config maps` that were previously configured during the installation of Development cluster setup.\n\n## Developer Tools Pipeline\n\nTo enable application compatibility between Kubernetes and OpenShift, the `Jenkinsfile` is consistent between pipeline registration with\nboth platforms. Also, the Docker images are built from\n[UBI images](https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image)\nso that their containers can run on both platforms.\n\nThese are the stages in the pipeline and a description of what each stage does. The **bold stage names** indicate\nthe stages that are required; the ***italics stage names*** indicate optional stages that can be deleted or will be ignored if the tool\nsupporting the stage is not installed. These stages represent a typical production pipeline flow for a cloud-native application.\n- **Setup**: Clones the code into the pipeline\n- **Build**: Runs the build commands for the code\n- **Test**:\tValidates the unit tests for the code\n- ***Publish pacts***:\tPublishes any pact contracts that have been defined\n- ***Sonar scan***: Runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment**: Validates the OpenShift or IKS environment configuration is valid\n- **Build image**: Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**:\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Health Check**: Validates the Health Endpoint of the deployed application\n- ***Package Helm Chart***: Stores the tagged version of the Helm chart in Artifactory\n- ***Trigger CD Pipeline***: This is a GitOps stage that will update the build number in designated git repo and trigger ArgoCD for deployment to **test**\n\n## Registering Pipelines\n\nThe [<Globals name=\"templates\" />](/starterkits) are a good place to start to see how `Jenkinsfile` and `Dockerfile` should be configured for use in a Jenkins CI pipeline. To register your git repo, use the [IGC CLI](/getting-started/cli). This command automates a number of manual steps you would have to do with Jenkins, including: managing secrets, webhooks, and pipeline registration in the Jenkins tools.\n\n```bash\nigc pipeline\n```\n\nBy default, the pipeline will register into the `dev` namespace and will copy all the `configMaps` and `secrets` from the `tools` namespace to the `dev` namespace. This means the pipeline can execute, knowing it has access to the key information that enables it to integrate with both the cloud platform and the various development tools. See [Cluster Configuration](/tools/cluster-configuration) for more detailed information.\n\n### Registering Pipeline in new namespace\n\nYou can use any namespace you want to register a pipeline. If you add `-n` or `namespace` to your `igc pipeline` command, it will create a new namespace if it doesn't already exist. It will copy the necessary `secrets` and `configMaps` into that namespace and configure the build agents pods to run in that namespace.\n\n```bash\nigc pipeline -n team-one\n```\n\nThis is good if you have various squads, teams, pairs or students working in the same Development Tools environment.\n\n## Continuous deployment\n\nIn addition to continuous integration, the <Globals name=\"env\" /> also supports continuous delivery\nusing Artifactory and ArgoCD:\n\n<AnchorLinks small>\n  <AnchorLink to=\"/tools/artifactory\">Artifact Management with Artifactory</AnchorLink>\n  <AnchorLink to=\"/tools/argocd\">Continuous Delivery with ArgoCD</AnchorLink>\n</AnchorLinks>\n","type":"Mdx","contentDigest":"8327b44df2e9b6898ec26f2fcf99ec5e","counter":991,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Continuous Integration with Jenkins"},"exports":{},"rawBody":"---\ntitle: Continuous Integration with Jenkins\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nUse Jenkins to automate your continuous integration process\n\n</PageDescription>\n\n[Jenkins](https://jenkins.io/) is a self-contained, open source automation server that can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.\nIt is a perfect tool for helping manage continuous integration tasks for a wide range of software components.\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins that supports implementing and integrating continuous delivery pipelines into Jenkins.\n\nA continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines \"as code.\" The definition of a Jenkins Pipeline is typically written into a text file (called a [Jenkinsfile](https://jenkins.io/doc/pipeline/tour/hello-world/)) that in turn is checked into a project’s source control repository.\n\n### Pipelines\n\nPipelines offer a set of stages or steps that can be chained together to allow a level of software\nautomation. This automation can be tailored to the specific project requirements.\n\nYou can read more information about Jenkins Pipelines [here](https://jenkins.io/doc/book/pipeline/)\n\n### Stages\n\nPipelines are defined in a `Jenkinsfile` that sits in the root of your application code. It defines a number of stages. Each of the [<Globals name=\"templates\" />](/starterkits) includes a `Jenkinsfile` that offers a number of stages. The stages have been configured to complete the build, test, package, and deploy of the application code. Each stage can use the defined defined `secrets` and `config maps` that were previously configured during the installation of Development cluster setup.\n\n## Developer Tools Pipeline\n\nTo enable application compatibility between Kubernetes and OpenShift, the `Jenkinsfile` is consistent between pipeline registration with\nboth platforms. Also, the Docker images are built from\n[UBI images](https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image)\nso that their containers can run on both platforms.\n\nThese are the stages in the pipeline and a description of what each stage does. The **bold stage names** indicate\nthe stages that are required; the ***italics stage names*** indicate optional stages that can be deleted or will be ignored if the tool\nsupporting the stage is not installed. These stages represent a typical production pipeline flow for a cloud-native application.\n- **Setup**: Clones the code into the pipeline\n- **Build**: Runs the build commands for the code\n- **Test**:\tValidates the unit tests for the code\n- ***Publish pacts***:\tPublishes any pact contracts that have been defined\n- ***Sonar scan***: Runs a sonar code scan of the source code and publishes the results to SonarQube\n- **Verify environment**: Validates the OpenShift or IKS environment configuration is valid\n- **Build image**: Builds the code into a Docker images and stores it in the IBM Cloud Image registry\n- **Deploy to DEV env**:\tDeploys the Docker image tagged version to `dev` namespace using Helm Chart\n- **Health Check**: Validates the Health Endpoint of the deployed application\n- ***Package Helm Chart***: Stores the tagged version of the Helm chart in Artifactory\n- ***Trigger CD Pipeline***: This is a GitOps stage that will update the build number in designated git repo and trigger ArgoCD for deployment to **test**\n\n## Registering Pipelines\n\nThe [<Globals name=\"templates\" />](/starterkits) are a good place to start to see how `Jenkinsfile` and `Dockerfile` should be configured for use in a Jenkins CI pipeline. To register your git repo, use the [IGC CLI](/getting-started/cli). This command automates a number of manual steps you would have to do with Jenkins, including: managing secrets, webhooks, and pipeline registration in the Jenkins tools.\n\n```bash\nigc pipeline\n```\n\nBy default, the pipeline will register into the `dev` namespace and will copy all the `configMaps` and `secrets` from the `tools` namespace to the `dev` namespace. This means the pipeline can execute, knowing it has access to the key information that enables it to integrate with both the cloud platform and the various development tools. See [Cluster Configuration](/tools/cluster-configuration) for more detailed information.\n\n### Registering Pipeline in new namespace\n\nYou can use any namespace you want to register a pipeline. If you add `-n` or `namespace` to your `igc pipeline` command, it will create a new namespace if it doesn't already exist. It will copy the necessary `secrets` and `configMaps` into that namespace and configure the build agents pods to run in that namespace.\n\n```bash\nigc pipeline -n team-one\n```\n\nThis is good if you have various squads, teams, pairs or students working in the same Development Tools environment.\n\n## Continuous deployment\n\nIn addition to continuous integration, the <Globals name=\"env\" /> also supports continuous delivery\nusing Artifactory and ArgoCD:\n\n<AnchorLinks small>\n  <AnchorLink to=\"/tools/artifactory\">Artifact Management with Artifactory</AnchorLink>\n  <AnchorLink to=\"/tools/argocd\">Continuous Delivery with ArgoCD</AnchorLink>\n</AnchorLinks>\n","fileAbsolutePath":"/home/runner/work/ibm-garage-developer-guide/ibm-garage-developer-guide/src/pages/tools/jenkins/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","3273249464","63531786","63531786","768070550"]}